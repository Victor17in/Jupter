{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Job.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "ConKBzr2Oii4",
        "outputId": "bdb41ef7-3bde-4c47-9e67-646cda10b4ee"
      },
      "source": [
        "import ROOT\n",
        "import glob\n",
        "import importlib\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import JobStatistics\n",
        "\n",
        "#======================================================================\n",
        "\n",
        "class Job(object):\n",
        "    \"\"\"This class is a carrier class for a given analysis. It takes care of the technical details like\n",
        "    file writing, setting up the input tree and providing statistics about the status of the analysis.    \n",
        "    \"\"\"\n",
        "    def __init__(self, processName, configuration, inputLocation):\n",
        "        super(Job, self).__init__()\n",
        "        #Configurables\n",
        "        self.Name       = processName\n",
        "        self.Configuration = configuration\n",
        "        self.MaxEvents     = configuration[\"MaxEvents\"]\n",
        "        self.InputFiles    = glob.glob(inputLocation)\n",
        "\n",
        "        # Outputs\n",
        "        self.OutputFileLocation = configuration[\"OutputDirectory\"] + processName\n",
        "        self.OutputFile = None\n",
        "\n",
        "        # Classes - InputTree and Analysis have to be created later otherwise parallel running does not work\n",
        "        self.InputTree     = None\n",
        "        self.Analysis      = None\n",
        "        self.JobStatistics = JobStatistics.JobStatistics(self.Configuration[\"MaxEvents\"], self.Configuration[\"Batch\"])\n",
        "\n",
        "    #Setup functions\n",
        "    def setupTree(self):\n",
        "      tree = ROOT.TChain(\"mini\")\n",
        "      for filename in self.InputFiles:\n",
        "        self.log(\"Adding file: \" + filename)\n",
        "        tree.Add(filename)\n",
        "      return tree\n",
        "                    \n",
        "    def createAnalysis(self, analysisName):\n",
        "        analysisName = self.Configuration[\"Analysis\"]\n",
        "        importedAnalysisModule = importlib.import_module(\"Analysis.\" + analysisName)\n",
        "        analysis = getattr(importedAnalysisModule, analysisName)(self.Name)\n",
        "        analysis.Store.initializeTuple(self.InputTree)\n",
        "        analysis.setIsData(\"data\" in self.Name.lower())\n",
        "        return analysis\n",
        "    \n",
        "    #Execution functions                    \n",
        "    def run(self):\n",
        "      self.initialize()\n",
        "      self.execute()\n",
        "      self.finalize()\n",
        "      \n",
        "    def initialize(self):\n",
        "      self.log(\"Intialization phase\")\n",
        "      self.JobStatistics.resetTimer()\n",
        "      self.OutputFile = ROOT.TFile.Open(self.OutputFileLocation + \".root\",\"RECREATE\")\n",
        "      self.InputTree = self.setupTree()\n",
        "      self.Analysis  = self.createAnalysis(self.Configuration[\"Analysis\"])\n",
        "      self.determineMaxEvents()\n",
        "      self.Analysis.doInitialization()\n",
        "        \n",
        "    def execute(self):\n",
        "      self.log(\"Now looping over %d events\" % self.MaxEvents)\n",
        "      for n in xrange(self.MaxEvents):\n",
        "        self.JobStatistics.updateStatus(n)\n",
        "        self.InputTree.GetEntry(n)\n",
        "        self.Analysis.doAnalysis()\n",
        "            \n",
        "    def finalize(self):\n",
        "      self.JobStatistics.updateStatus(self.MaxEvents, True)\n",
        "      if not self.Configuration[\"Batch\"]:\n",
        "          print \"\"\n",
        "      self.Analysis.doFinalization()\n",
        "      self.OutputFile.Close()\n",
        "      self.log(\"finished successfully. Total time: %4.0fs\" % self.JobStatistics.elapsedTime())\n",
        "\n",
        "\n",
        "    # Helper functions\n",
        "    def determineMaxEvents(self):\n",
        "      nentries = self.InputTree.GetEntries()\n",
        "      if nentries==0:\n",
        "        self.log(\"Empty files! Abort!\")\n",
        "        sys.exit(1)\n",
        "      \n",
        "      if self.MaxEvents > nentries:\n",
        "        self.MaxEvents = nentries\n",
        "      \n",
        "      self.MaxEvents = int(self.MaxEvents*self.Configuration[\"Fraction\"]) \n",
        "      self.JobStatistics.setMaxEvents(self.MaxEvents)\n",
        "\n",
        "    def log(self, message):\n",
        "      print time.ctime() + \" Job \" + self.Name + \": \" + message\n",
        "              "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-0cb8985f87f5>\"\u001b[0;36m, line \u001b[0;32m73\u001b[0m\n\u001b[0;31m    print \"\"\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"\")?\n"
          ]
        }
      ]
    }
  ]
}