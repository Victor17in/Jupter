{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RunScript.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJYvt1H1f4bd5f1qpA+I0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victor17in/Jupter/blob/main/RunScript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "335YLZI92JCQ"
      },
      "source": [
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import ROOT\n",
        "import importlib\n",
        "import Analysis.Job as Job\n",
        "import Analysis.Disclaimer as DC\n",
        "from multiprocessing import Pool \n",
        "\n",
        "def buildProcessingDict(configuration, samples):\n",
        "    if samples == \"\": \n",
        "        return configuration.Processes\n",
        "    processingDict = {}\n",
        "    listOfSamples = [substring.strip() for substring in samples.split(',')]\n",
        "    for sample in listOfSamples:\n",
        "        try:\n",
        "            processingDict[sample] = configuration.Processes[sample]\n",
        "        except :\n",
        "            print \"Name of Sample %s not recognized. Sample was not added to processing list!\" % sample\n",
        "    return processingDict\n",
        "\n",
        "def checkAnalysis(configuration, analysisOption):\n",
        "    analysisName = analysisOption if analysisOption != \"\" else configuration.Job[\"Analysis\"]\n",
        "    try:\n",
        "        importedAnalysisModule = importlib.import_module(\"Analysis.\" + analysisName)\n",
        "        configuration.Job[\"Analysis\"] = analysisName\n",
        "    except ImportError:\n",
        "        print \"Error when trying to read the analysis code for %s. Please check name validity\" % analysisName\n",
        "        sys.exit(1)\n",
        "\n",
        "def BuildJob(configuration, processName, fileLocation):\n",
        "    job = Job.Job(processName, configuration, fileLocation )\n",
        "    return job\n",
        "\n",
        "\n",
        "def SortJobsBySize(jobs):  \n",
        "    def jobSize(job):\n",
        "        return sum([os.lstat(f).st_size for f in job.InputFiles])\n",
        "    return sorted(jobs, key=jobSize, reverse=True)\n",
        "\n",
        "def RunJob(job):\n",
        "    job.run()\n",
        "\n",
        " \n",
        "#======================================================================\n",
        "def main( argv ):\n",
        "    \"\"\"\n",
        "    Main function to be executed when starting the code.\n",
        "    \"\"\"\n",
        "    DC.printDisclaimer()\n",
        "    \n",
        "    # global configuration\n",
        "    parser = argparse.ArgumentParser( description = 'Analysis Tool using XMLs' )\n",
        "    parser.add_argument('-n', '--nWorkers',   default=4,                                 type=int,   help='number of workers' )  \n",
        "    parser.add_argument('-p', '--parallel',   default=False,   action='store_const',     const=True, help='enables running in parallel')\n",
        "    parser.add_argument('-c', '--configfile', default=\"Configurations/Configuration.py\", type=str,   help='files to be analysed')\n",
        "    parser.add_argument('-a', '--analysis',   default=\"\"                               , type=str,   help='overrides the analysis specified in configuration file')\n",
        "    parser.add_argument('-s', '--samples',    default=\"\"                               , type=str,   help='string with comma separated list of samples to analyse')\n",
        "    parser.add_argument('-o', '--output',     default=\"\"                               , type=str,   help='name of the output directory')\n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    configModuleName = args.configfile.replace(\"/\", \".\").replace(\".py\",\"\")\n",
        "    configuration = importlib.import_module(configModuleName)\n",
        "  \n",
        "    configuration.Job[\"OutputDirectory\"] = args.output + \"/\" if args.output != \"\" else configuration.Job[\"OutputDirectory\"]\n",
        "    if not os.path.exists(configuration.Job[\"OutputDirectory\"]):\n",
        "        os.makedirs(configuration.Job[\"OutputDirectory\"])\n",
        "\n",
        "    checkAnalysis(configuration, args.analysis)\n",
        "    processingDict = buildProcessingDict(configuration, args.samples)\n",
        "\n",
        "    if (args.parallel):\n",
        "        configuration.Job[\"Batch\"] = True\n",
        "        jobs = [BuildJob(configuration.Job, processName, fileLocation) for processName, fileLocation in processingDict.items()]\n",
        "        jobs = SortJobsBySize(jobs)\n",
        "        pool = Pool(processes=args.nWorkers)              # start with n worker processes\n",
        "        pool.map(RunJob, jobs, chunksize=1)\n",
        "\n",
        "    else:\n",
        "        for processName, fileLocation in processingDict.items():\n",
        "            RunJob(BuildJob(configuration.Job, processName, fileLocation))      \n",
        "  \n",
        "#======================================================================   \n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Here the code should appear that is executed when running the plotter directly\n",
        "    (and not import it in another python file via 'import Plotter')\n",
        "    \"\"\"\n",
        "   \n",
        "    main( sys.argv[1:] )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}