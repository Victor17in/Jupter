{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER>\n",
    "    <a href=\"http://opendata.atlas.cern/release/2020/documentation/notebooks/intro.html\" class=\"icons\"><img src=\"../../images/ATLASOD.gif\" style=\"width:40%\"></a>\n",
    "</CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple introductional notebook to HEP analysis in python\n",
    "<p> In this notebook you can find an easy set of commands that show the basic computing techniques commonly used in high energy  physics (HEP) analyzes. It also shows how to create a histogram, fill it and draw it. Moreover it is an introduction to [ROOT](https://root.cern.ch/) too. At the end you get a plot with the number of leptons.</p>\n",
    "\n",
    "\n",
    "<CENTER><h1>Simple pyROOT notebook example</h1></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library used is ROOT - a scientific software framework that provides all the functionalities needed to deal with big data processing, statistical analysis, visualisation and storage.\n",
    "\n",
    "First of all ROOT is imported to read the files in the _.root_ data format. A _.root_ file consists of a tree having branches and leaves. At this point you could also import further programs that contain other formulas that you maybe use more often. But here we don't import other programs to keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/02\n"
     ]
    }
   ],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to activate the interactive visualisation of the histogram that is later created we can use the JSROOT magic \n",
    "\n",
    "*(if gives yo an error, don't worry, it maybe that your ROOT is simply too old)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following analysis is searching for events where [Z bosons](https://en.wikipedia.org/wiki/W_and_Z_bosons) decay to two leptons of same flavour and opposite charge (to be seen for example in the [Feynman diagram](https://en.wikipedia.org/wiki/Feynman_diagram))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/Z_ElectronPositron.png\" style=\"width:30%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to open the data that we want to analyze. As described above the data is stored in a _*.root_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile.Open(\"http://opendata.atlas.cern/release/samples/MC/mc_105987.WZ.root\")\n",
    "g = ROOT.TFile.Open(\"http://opendata.atlas.cern/release/samples/MC/mc_105985.WW.root\") ## 8 TeV sample\n",
    "##f = ROOT.TFile.Open(\"/home/student/datasets/MC/mc_105987.WZ.root\") ## local file exampl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data is opened we create a canvas on which we can draw a histogram. If we do not have a canvas we cannot see our histogram at the end. Its name is _Canvas_ and its header is _a first way to plot a variable_. The two following arguments define the width and the height of the canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = ROOT.TCanvas(\"Canvas\",\"a first way to plot a variable\",800,600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define a tree named _tree_ to get the data out of the _*.root_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = f.Get(\"mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = g.Get(\"mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver o que está dentro de \"mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :mini      : 4-vectors + variables required for scaling factors     *\n",
      "*Entries :   500000 : Total =       149029090 bytes  File  Size =   69445225 *\n",
      "*        :          : Tree compression factor =   2.15                       *\n",
      "******************************************************************************\n",
      "*Br    0 :runNumber : runNumber/I                                            *\n",
      "*Entries :   500000 : Total  Size=    2000881 bytes  File Size  =      10266 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression= 194.85     *\n",
      "*............................................................................*\n",
      "*Br    1 :eventNumber : eventNumber/I                                        *\n",
      "*Entries :   500000 : Total  Size=    2000899 bytes  File Size  =    1015696 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   1.97     *\n",
      "*............................................................................*\n",
      "*Br    2 :channelNumber : channelNumber/I                                    *\n",
      "*Entries :   500000 : Total  Size=    2000917 bytes  File Size  =      10282 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression= 194.55     *\n",
      "*............................................................................*\n",
      "*Br    3 :mcWeight  : mcWeight/F                                             *\n",
      "*Entries :   500000 : Total  Size=    2000872 bytes  File Size  =      10252 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression= 195.12     *\n",
      "*............................................................................*\n",
      "*Br    4 :pvxp_n    : pvxp_n/I                                               *\n",
      "*Entries :   500000 : Total  Size=    2000854 bytes  File Size  =     452161 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   4.42     *\n",
      "*............................................................................*\n",
      "*Br    5 :vxp_z     : vxp_z/F                                                *\n",
      "*Entries :   500000 : Total  Size=    2000845 bytes  File Size  =    1858096 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br    6 :scaleFactor_PILEUP : scaleFactor_PILEUP/F                          *\n",
      "*Entries :   500000 : Total  Size=    2000962 bytes  File Size  =      45575 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=  43.89     *\n",
      "*............................................................................*\n",
      "*Br    7 :scaleFactor_ELE : scaleFactor_ELE/F                                *\n",
      "*Entries :   500000 : Total  Size=    2000935 bytes  File Size  =     737206 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   2.71     *\n",
      "*............................................................................*\n",
      "*Br    8 :scaleFactor_MUON : scaleFactor_MUON/F                              *\n",
      "*Entries :   500000 : Total  Size=    2000944 bytes  File Size  =     852351 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   2.35     *\n",
      "*............................................................................*\n",
      "*Br    9 :scaleFactor_BTAG : scaleFactor_BTAG/F                              *\n",
      "*Entries :   500000 : Total  Size=    2000944 bytes  File Size  =    1270799 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   1.57     *\n",
      "*............................................................................*\n",
      "*Br   10 :scaleFactor_TRIGGER : scaleFactor_TRIGGER/F                        *\n",
      "*Entries :   500000 : Total  Size=    2000971 bytes  File Size  =    1150642 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   1.74     *\n",
      "*............................................................................*\n",
      "*Br   11 :scaleFactor_JVFSF : scaleFactor_JVFSF/F                            *\n",
      "*Entries :   500000 : Total  Size=    2000953 bytes  File Size  =      10297 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression= 194.27     *\n",
      "*............................................................................*\n",
      "*Br   12 :scaleFactor_ZVERTEX : scaleFactor_ZVERTEX/F                        *\n",
      "*Entries :   500000 : Total  Size=    2000971 bytes  File Size  =     943242 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   2.12     *\n",
      "*............................................................................*\n",
      "*Br   13 :trigE     : trigE/O                                                *\n",
      "*Entries :   500000 : Total  Size=     503611 bytes  File Size  =     115545 *\n",
      "*Baskets :       36 : Basket Size=      13312 bytes  Compression=   4.35     *\n",
      "*............................................................................*\n",
      "*Br   14 :trigM     : trigM/O                                                *\n",
      "*Entries :   500000 : Total  Size=     503611 bytes  File Size  =     115719 *\n",
      "*Baskets :       36 : Basket Size=      13312 bytes  Compression=   4.34     *\n",
      "*............................................................................*\n",
      "*Br   15 :passGRL   : passGRL/O                                              *\n",
      "*Entries :   500000 : Total  Size=     503691 bytes  File Size  =       6036 *\n",
      "*Baskets :       36 : Basket Size=      13312 bytes  Compression=  83.28     *\n",
      "*............................................................................*\n",
      "*Br   16 :hasGoodVertex : hasGoodVertex/O                                    *\n",
      "*Entries :   500000 : Total  Size=     503931 bytes  File Size  =      24837 *\n",
      "*Baskets :       36 : Basket Size=      13312 bytes  Compression=  20.25     *\n",
      "*............................................................................*\n",
      "*Br   17 :lep_n     : lep_n/i                                                *\n",
      "*Entries :   500000 : Total  Size=    2000845 bytes  File Size  =     207357 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   9.65     *\n",
      "*............................................................................*\n",
      "*Br   18 :lep_truthMatched : lep_truthMatched[lep_n]/O                       *\n",
      "*Entries :   500000 : Total  Size=    2662344 bytes  File Size  =     771381 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   3.45     *\n",
      "*............................................................................*\n",
      "*Br   19 :lep_trigMatched : lep_trigMatched[lep_n]/s                         *\n",
      "*Entries :   500000 : Total  Size=    3323244 bytes  File Size  =     942499 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   3.53     *\n",
      "*............................................................................*\n",
      "*Br   20 :lep_pt    : lep_pt[lep_n]/F                                        *\n",
      "*Entries :   500000 : Total  Size=    4644953 bytes  File Size  =    3002520 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.55     *\n",
      "*............................................................................*\n",
      "*Br   21 :lep_eta   : lep_eta[lep_n]/F                                       *\n",
      "*Entries :   500000 : Total  Size=    4644966 bytes  File Size  =    3096337 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.50     *\n",
      "*............................................................................*\n",
      "*Br   22 :lep_phi   : lep_phi[lep_n]/F                                       *\n",
      "*Entries :   500000 : Total  Size=    4644966 bytes  File Size  =    3098861 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.50     *\n",
      "*............................................................................*\n",
      "*Br   23 :lep_E     : lep_E[lep_n]/F                                         *\n",
      "*Entries :   500000 : Total  Size=    4644940 bytes  File Size  =    3014217 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.54     *\n",
      "*............................................................................*\n",
      "*Br   24 :lep_z0    : lep_z0[lep_n]/F                                        *\n",
      "*Entries :   500000 : Total  Size=    4644953 bytes  File Size  =    3121758 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.49     *\n",
      "*............................................................................*\n",
      "*Br   25 :lep_charge : lep_charge[lep_n]/F                                   *\n",
      "*Entries :   500000 : Total  Size=    4645005 bytes  File Size  =     941553 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   4.93     *\n",
      "*............................................................................*\n",
      "*Br   26 :lep_type  : lep_type[lep_n]/i                                      *\n",
      "*Entries :   500000 : Total  Size=    4644972 bytes  File Size  =     928008 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   5.00     *\n",
      "*............................................................................*\n",
      "*Br   27 :lep_flag  : lep_flag[lep_n]/i                                      *\n",
      "*Entries :   500000 : Total  Size=    4644972 bytes  File Size  =    1344725 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   3.45     *\n",
      "*............................................................................*\n",
      "*Br   28 :lep_ptcone30 : lep_ptcone30[lep_n]/F                               *\n",
      "*Entries :   500000 : Total  Size=    4645031 bytes  File Size  =    1335102 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   3.48     *\n",
      "*............................................................................*\n",
      "*Br   29 :lep_etcone20 : lep_etcone20[lep_n]/F                               *\n",
      "*Entries :   500000 : Total  Size=    4645031 bytes  File Size  =    3050617 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.52     *\n",
      "*............................................................................*\n",
      "*Br   30 :lep_trackd0pvunbiased : lep_trackd0pvunbiased[lep_n]/F             *\n",
      "*Entries :   500000 : Total  Size=    4645148 bytes  File Size  =    3116736 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.49     *\n",
      "*............................................................................*\n",
      "*Br   31 :lep_tracksigd0pvunbiased : lep_tracksigd0pvunbiased[lep_n]/F       *\n",
      "*Entries :   500000 : Total  Size=    4645187 bytes  File Size  =    2955447 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.57     *\n",
      "*............................................................................*\n",
      "*Br   32 :met_et    : met_et/F                                               *\n",
      "*Entries :   500000 : Total  Size=    2000854 bytes  File Size  =    1795315 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   1.11     *\n",
      "*............................................................................*\n",
      "*Br   33 :met_phi   : met_phi/F                                              *\n",
      "*Entries :   500000 : Total  Size=    2000863 bytes  File Size  =    1853970 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br   34 :jet_n     : jet_n/i                                                *\n",
      "*Entries :   500000 : Total  Size=    2000845 bytes  File Size  =     316369 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   6.32     *\n",
      "*............................................................................*\n",
      "*Br   35 :alljet_n  : alljet_n/i                                             *\n",
      "*Entries :   500000 : Total  Size=    2000872 bytes  File Size  =     329028 *\n",
      "*Baskets :        5 : Basket Size=     810496 bytes  Compression=   6.08     *\n",
      "*............................................................................*\n",
      "*Br   36 :jet_pt    : jet_pt[alljet_n]/F                                     *\n",
      "*Entries :   500000 : Total  Size=    4927265 bytes  File Size  =    3283554 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.50     *\n",
      "*............................................................................*\n",
      "*Br   37 :jet_eta   : jet_eta[alljet_n]/F                                    *\n",
      "*Entries :   500000 : Total  Size=    4927278 bytes  File Size  =    3393813 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.45     *\n",
      "*............................................................................*\n",
      "*Br   38 :jet_phi   : jet_phi[alljet_n]/F                                    *\n",
      "*Entries :   500000 : Total  Size=    4927278 bytes  File Size  =    3394960 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.45     *\n",
      "*............................................................................*\n",
      "*Br   39 :jet_E     : jet_E[alljet_n]/F                                      *\n",
      "*Entries :   500000 : Total  Size=    4927252 bytes  File Size  =    3300558 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.49     *\n",
      "*............................................................................*\n",
      "*Br   40 :jet_m     : jet_m[alljet_n]/F                                      *\n",
      "*Entries :   500000 : Total  Size=    4927252 bytes  File Size  =    3279779 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.50     *\n",
      "*............................................................................*\n",
      "*Br   41 :jet_jvf   : jet_jvf[alljet_n]/F                                    *\n",
      "*Entries :   500000 : Total  Size=    4927278 bytes  File Size  =    2950030 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.67     *\n",
      "*............................................................................*\n",
      "*Br   42 :jet_trueflav : jet_trueflav[alljet_n]/I                            *\n",
      "*Entries :   500000 : Total  Size=    4927336 bytes  File Size  =     990880 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   4.97     *\n",
      "*............................................................................*\n",
      "*Br   43 :jet_truthMatched : jet_truthMatched[alljet_n]/I                    *\n",
      "*Entries :   500000 : Total  Size=    4927388 bytes  File Size  =     865601 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   5.69     *\n",
      "*............................................................................*\n",
      "*Br   44 :jet_SV0   : jet_SV0[alljet_n]/F                                    *\n",
      "*Entries :   500000 : Total  Size=    4927278 bytes  File Size  =    1021060 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   4.83     *\n",
      "*............................................................................*\n",
      "*Br   45 :jet_MV1   : jet_MV1[alljet_n]/F                                    *\n",
      "*Entries :   500000 : Total  Size=    4927278 bytes  File Size  =    3106137 *\n",
      "*Baskets :        9 : Basket Size=     810496 bytes  Compression=   1.59     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "tree.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.GetEntries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a histogram that will later be placed on this canvas. Its name is _variable_ and the header of the histogram is _Example plot: Number of leptons_. The three following arguments indicate that this histogram contains 4 so called bins which have a range from 0 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = ROOT.TH1F(\"variable\",\"Example plot: Momento dos jatos; GeV ; Eventos \",10,0,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines are a loop that goes over the data that is stored in the tree and fills the histogram _h_ that we already defined. In this first notebook we don't do any cuts to keep it simple. Accordingly the loop fills the histogram for each event stored in the tree. After the program has looped over all the data it prints the word __Done!__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cppyy.LowLevelView"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tree.jet_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventWeight = tree.mcWeight*tree.scaleFactor_PILEUP*tree.scaleFactor_ZVERTEX\n",
    "scalefactor = tree.scaleFactor_MUON*tree.scaleFactor_ELE*tree.scaleFactor_TRIGGER\n",
    "weight = eventWeight*scalefactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "type(weight)\n",
    "print(tree.mcWeight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se você for utilizar uma variável com um vetor usar dessa forma por exemplo:\n",
    "## Para : jet_eta   : jet_eta[alljet_n]/F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para os elementos (i) da folha jet_pt (presente na árvore mini) que contém valores referentes aos jatos (alljet_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demora em torno de 5 minutos para rodar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão por mil dentro do for para encontrar o resultado em GeV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e5a38875792f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet_pt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for event in tree:\n",
    "    for i in tree.jet_pt:\n",
    "        if (i/1000)>100:\n",
    "            hist.Fill(i/1000, weight)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for event in tree2:\n",
    "#     for i in tree2.jet_pt:\n",
    "#         if (i/1000)>100:\n",
    "#             hist.Fill(i/1000)\n",
    "    \n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filling the histogram we want to see the results of the analysis. First we draw the histogram on the canvas and then the canvas on which the histogram lies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.SetFillColor(11)\n",
    "hist.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will rescale the histogram to one (1).\n",
    "This will allow to see proportions in the histogram itself.\n",
    "**This is called normalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = hist.Integral()\n",
    "hist.Scale(1/scale)\n",
    "hist.SetFillColor(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.Draw()\n",
    "canvas.Draw(\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Done!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
